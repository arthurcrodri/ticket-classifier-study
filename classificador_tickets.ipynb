{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc65d8e2",
   "metadata": {},
   "source": [
    "# Projeto: Classificador de Chamados de Suporte (TicketClassifier)\n",
    "Este script demonstra competências em:\n",
    "1. SQL (Criação e consulta de banco de dados)\n",
    "2. Pandas/Numpy (Manipulação de dados)\n",
    "3. TensorFlow/Keras (Criação de Rede Neural para NLP)\n",
    "4. Matplotlib (Visualização de métricas de treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2297f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Configuração para evitar logs excessivos do TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(f\"Bibliotecas carregadas. TensorFlow versão: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589aad5",
   "metadata": {},
   "source": [
    "### Simulação de Banco de Dados (SQL)\n",
    "Criamos um banco SQLite em memória e populamos com dados sintéticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- PREPARANDO BANCO DE DADOS (SQL) ---\")\n",
    "\n",
    "# Conexão em memória (não cria arquivo físico)\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Criação da tabela\n",
    "cursor.execute('''\n",
    "    CREATE TABLE chamados (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        descricao TEXT NOT NULL,\n",
    "        categoria TEXT NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Dados de exemplo (Seed Data)\n",
    "dados_base = [\n",
    "    (\"O servidor caiu e não consigo acessar a rede\", \"Infraestrutura\"),\n",
    "    (\"A internet está muito lenta no setor financeiro\", \"Infraestrutura\"),\n",
    "    (\"Não consigo logar no VPN de casa\", \"Infraestrutura\"),\n",
    "    (\"Wifi não conecta no celular corporativo\", \"Infraestrutura\"),\n",
    "    (\"O switch do terceiro andar está piscando vermelho\", \"Infraestrutura\"),\n",
    "    \n",
    "    (\"Meu mouse parou de funcionar\", \"Hardware\"),\n",
    "    (\"Monitor piscando e com cores estranhas\", \"Hardware\"),\n",
    "    (\"Impressora fazendo barulho e não imprime\", \"Hardware\"),\n",
    "    (\"O teclado está com teclas presas\", \"Hardware\"),\n",
    "    (\"A bateria do notebook não carrega\", \"Hardware\"),\n",
    "    \n",
    "    (\"Preciso instalar o Python e o VS Code\", \"Software\"),\n",
    "    (\"Erro ao compilar o código no pipeline\", \"Software\"),\n",
    "    (\"Tela azul da morte no Windows após atualização\", \"Software\"),\n",
    "    (\"O Excel trava quando abro a planilha de custos\", \"Software\"),\n",
    "    (\"Preciso de acesso à pasta compartilhada\", \"Software\")\n",
    "]\n",
    "\n",
    "# Multiplicando dados para ter volume mínimo para Deep Learning (Data Augmentation simples)\n",
    "dados_finais = dados_base * 40  # Total de 600 exemplos\n",
    "\n",
    "cursor.executemany('INSERT INTO chamados (descricao, categoria) VALUES (?, ?)', dados_finais)\n",
    "conn.commit()\n",
    "print(f\"{len(dados_finais)} chamados inseridos no banco SQL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3dde0",
   "metadata": {},
   "source": [
    "### Extração e Tratamento (Pandas & Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f01294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- EXTRAÇÃO E PROCESSAMENTO (PANDAS/NUMPY) ---\")\n",
    "\n",
    "# Leitura SQL -> DataFrame Pandas\n",
    "query = \"SELECT descricao, categoria FROM chamados\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Visualizando distribuição\n",
    "print(\"Distribuição das classes:\")\n",
    "print(df['categoria'].value_counts())\n",
    "\n",
    "# Transformando categorias (Texto) em Números (0, 1, 2)\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['categoria'])\n",
    "classes_nomes = le.classes_\n",
    "print(f\"Classes mapeadas: {classes_nomes}\")\n",
    "\n",
    "# Conversão para Numpy Arrays\n",
    "X = df['descricao'].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Divisão Treino (80%) e Teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Tamanho Treino: {len(X_train)} | Tamanho Teste: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f9d86",
   "metadata": {},
   "source": [
    "### Vetorização e Modelo (TensorFlow/Deep Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- CONSTRUINDO REDE NEURAL (TENSORFLOW) ---\")\n",
    "\n",
    "# Parâmetros de NLP\n",
    "VOCAB_SIZE = 1000  # Máximo de palavras no vocabulário\n",
    "SEQ_LENGTH = 20    # Tamanho fixo da frase (padding)\n",
    "\n",
    "# Camada de Vetorização (Texto -> Números Inteiros)\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=SEQ_LENGTH\n",
    ")\n",
    "\n",
    "# Adaptar o vetorizador ao nosso texto de treino (Aprender o vocabulário)\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n",
    "# Construção do Modelo Sequential\n",
    "model = keras.Sequential([\n",
    "    # Entrada: String bruta\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    \n",
    "    # Vetorização\n",
    "    vectorize_layer,\n",
    "    \n",
    "    # Embedding: Transforma índices em vetores densos (significado semântico)\n",
    "    layers.Embedding(input_dim=VOCAB_SIZE + 1, output_dim=16),\n",
    "    \n",
    "    # Pooling: Média dos vetores para simplificar (GlobalAveragePooling1D é muito rápido)\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    \n",
    "    # Dense: Camada oculta para aprendizado\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    \n",
    "    # Saída: 3 neurônios (softw, hardw, infra) com Softmax para probabilidade\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c95fb5",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- INICIANDO TREINAMENTO ---\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=15,\n",
    "    verbose=1 # Mostra barra de progresso\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91354550",
   "metadata": {},
   "source": [
    "### Visualização (Matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de242f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- GERANDO GRÁFICOS (MATPLOTLIB) ---\")\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Gráfico de Acurácia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Acurácia Treino')\n",
    "plt.plot(history.history['val_accuracy'], label='Acurácia Validação')\n",
    "plt.title('Evolução da Acurácia')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Gráfico de Perda\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Perda Treino')\n",
    "plt.plot(history.history['val_loss'], label='Perda Validação')\n",
    "plt.title('Evolução do Erro (Loss)')\n",
    "plt.xlabel('Épocas')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "nome_arquivo = 'grafico_performance.png'\n",
    "plt.savefig(nome_arquivo)\n",
    "print(f\"Gráfico salvo como '{nome_arquivo}' na pasta atual.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e7a64",
   "metadata": {},
   "source": [
    "### Teste Prático (Inferência)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7974f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- TESTE DE INFERÊNCIA ---\")\n",
    "\n",
    "def classificar_texto(texto):\n",
    "    # O modelo espera um Tensor\n",
    "    predicoes = model.predict(tf.constant([texto]), verbose=0)\n",
    "    indice_classe = np.argmax(predicoes)\n",
    "    confianca = np.max(predicoes)\n",
    "    nome_classe = classes_nomes[indice_classe]\n",
    "    return nome_classe, confianca\n",
    "\n",
    "# Testes manuais\n",
    "frases_teste = [\n",
    "    \"O servidor de arquivos parou de responder\",\n",
    "    \"Preciso que troque meu teclado, a tecla espaço quebrou\",\n",
    "    \"Não consigo instalar o docker no linux\"\n",
    "]\n",
    "\n",
    "print(f\"{'TEXTO':<55} | {'PREVISÃO':<15} | {'CONFIANÇA'}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for frase in frases_teste:\n",
    "    categoria, conf = classificar_texto(frase)\n",
    "    print(f\"{frase:<55} | {categoria:<15} | {conf:.1%}\")\n",
    "\n",
    "print(\"\\nScript finalizado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
